actor_entropy,actor_loss,actor_target_entropy,alpha_loss,alpha_value,batch_reward,critic_loss,duration,episode,episode_reward,step
3.761451332569122,-1.8539417075365783,-6.0,0.81319489762187,0.08330748151862587,0.8697618011385202,5.605249256305396,4.901774168014526,12.0,277.0347783040736,5400
3.6925278933842978,-2.5824853881200154,-6.0,0.5644397140211529,0.05821248271384751,0.8314455149239964,0.2752114364670383,5.630444288253784,13.0,555.7205597879788,5850
